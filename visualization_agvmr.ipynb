{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\experiment\\TKDE\\lgi\\LGI4temporalgrounding-master\\src\\utils\\tensorboard_utils.py:5: The name tf.disable_v2_behavior is deprecated. Please use tf.compat.v1.disable_v2_behavior instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\1\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "getattr(tqdm, '_instances', {}).clear()\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi']= 300\n",
    "import matplotlib.pyplot as plt\n",
    "#from IPython.display import Video, HTML\n",
    "\n",
    "# for visualization\n",
    "import cv2\n",
    "from moviepy.editor import *\n",
    "from moviepy.editor import VideoFileClip, concatenate_videoclips, clips_array\n",
    "\n",
    "from src.utils import io_utils, eval_utils\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rc('xtick', labelsize=10)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "FAST = True\n",
    "\n",
    "def expand_mask(mask, margin=2, height=12):\n",
    "    w = mask.shape[1]\n",
    "    out = [np.zeros((1,w,3), dtype=np.int64) for i in range(margin)]\n",
    "    for i in range(height):\n",
    "        out.append(mask)\n",
    "    for i in range(margin):\n",
    "        out.append(np.zeros((1,w,3), dtype=np.int64))\n",
    "    return np.concatenate(out, axis=0)\n",
    "\n",
    "def text_phantom(text, width=480):\n",
    "    # Availability is platform dependent\n",
    "    font = 'DejaVuSans-Bold'\n",
    "\n",
    "    # Create font\n",
    "    from PIL import ImageFont\n",
    "\n",
    "    pil_font = ImageFont.load_default()\n",
    "    # pil_font = ImageFont.truetype(font + \".ttf\", size=16,\n",
    "    #                               encoding=\"unic\")\n",
    "    text_width, text_height = pil_font.getsize(text)\n",
    "\n",
    "    # create a blank canvas with extra space between lines\n",
    "    canvas = Image.new('RGB', [width,20], (255, 255, 255))\n",
    "\n",
    "    # draw the text onto the canvas\n",
    "    draw = ImageDraw.Draw(canvas)\n",
    "    white = \"#000000\"\n",
    "    draw.text((0,0), text, font=pil_font, fill=white)\n",
    "\n",
    "    # (text, background): (black, while) -> (white, black)\n",
    "    return 255 - np.asarray(canvas)\n",
    "\n",
    "def sampling_idx(preds, policy=\"random\"):\n",
    "    idx = random.randint(0, len(preds[\"gts\"])-1)\n",
    "    if policy == \"random\":\n",
    "        return idx\n",
    "    elif policy == \"success\":\n",
    "        pred = preds[\"predictions\"][idx][0]\n",
    "        gt = preds[\"gts\"][idx]\n",
    "        while eval_utils.compute_tiou(pred, gt) < 0.8 or preds[\"gts\"][idx][0] < 15:\n",
    "            idx = random.randint(0, len(preds[\"gts\"])-1)\n",
    "            pred = preds[\"predictions\"][idx][0]\n",
    "            gt = preds[\"gts\"][idx]\n",
    "    elif policy == \"failure\":\n",
    "        pred = preds[\"predictions\"][idx][0]\n",
    "        gt = preds[\"gts\"][idx]\n",
    "        while eval_utils.compute_tiou(pred, gt) > 0.2:\n",
    "            idx = random.randint(0, len(preds[\"gts\"])-1)\n",
    "            pred = preds[\"predictions\"][idx][0]\n",
    "            gt = preds[\"gts\"][idx]\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bar(gt, pred, vlen, wbar):\n",
    "    # draw bar for GT and prediction\n",
    "    gt_idx = np.round(np.asarray(gt) / vlen * wbar).astype(np.int64)\n",
    "    pred_idx = np.round(np.asarray(pred) / vlen * wbar).astype(np.int64)\n",
    "    gt_mask, pred_mask = np.zeros((1,wbar,3)), np.zeros((1,wbar,3))\n",
    "    gt_mask[0, gt_idx[0]:gt_idx[1], 0] = 255 # Red color\n",
    "    pred_mask[0, pred_idx[0]:pred_idx[1], 2] = 255 # blue color\n",
    "\n",
    "    # expand masks for better visualization and concatenate them\n",
    "    bar = np.concatenate([expand_mask(gt_mask, margin=4), expand_mask(pred_mask)], axis=0)\n",
    "    return bar\n",
    "\n",
    "def make_result_video(preds, D, dt, vid_dir, policy=\"random\", visualize=True):\n",
    "    # sampling index and fetching relevant information\n",
    "    #policy = \"success\" # among [\"random\" | \"success\" | \"failure\"]\n",
    "    idx = sampling_idx(preds, policy)\n",
    "\n",
    "    vlen = preds[\"durations\"][idx]\n",
    "    qid = preds[\"qids\"][idx]\n",
    "    pred = preds[\"predictions\"][idx][0]\n",
    "    gt = preds[\"gts\"][idx]\n",
    "    vid = preds[\"vids\"][idx]\n",
    "    query = \" \".join(D.anns[qid][\"tokens\"])\n",
    "    assert vid == D.anns[qid][\"video_id\"], \"{} != {}\".format(vid, D.anns[qid][\"video_id\"])\n",
    "    assert vlen == D.anns[qid][\"duration\"], \"{} != {}\".format(vlen, D.anns[qid][\"duration\"])\n",
    "\n",
    "    # concatenate two videos where one for GT (red) and another for prediction (blue)\n",
    "    vw, mg, nw = 480, 20, 50 # video_width, margin, number of words at each line\n",
    "    if dt == \"anet\":\n",
    "        vname = vid[2:] + \".mp4\"\n",
    "    elif dt == \"charades\":\n",
    "        vname = vid + \".mp4\"\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "    vid_path = vid_dir + vname\n",
    "    print(f\"video path: {vid_path}\")\n",
    "    vid_GT = concatenate_videoclips([\n",
    "        VideoFileClip(vid_path,audio=False).subclip(0, gt[0]).margin(mg),\n",
    "        VideoFileClip(vid_path,audio=False).subclip(gt[0], min(gt[1],vlen)).margin(mg, color=(255,0,0)), # red\n",
    "        VideoFileClip(vid_path,audio=False).subclip(min(gt[1],vlen), vlen).margin(mg),\n",
    "        ])\n",
    "    vid_pred = concatenate_videoclips([\n",
    "        VideoFileClip(vid_path,audio=False).subclip(0, pred[0]).margin(mg),\n",
    "        VideoFileClip(vid_path,audio=False).subclip(pred[0], min(pred[1],vlen)).margin(mg, color=(0,0,255)), # blue\n",
    "        VideoFileClip(vid_path,audio=False).subclip(min(pred[1],vlen), vlen).margin(mg),\n",
    "        ])\n",
    "    cc = clips_array([[vid_GT, vid_pred]]).resize(width=vw)\n",
    "    if FAST:\n",
    "        if dt == \"charades\":\n",
    "            factor = np.round(vlen / 20)\n",
    "        else:\n",
    "            factor = np.round(vlen / 30)\n",
    "        print(f\"speedup factor: {factor}\")\n",
    "        cc = cc.speedx(factor=factor)\n",
    "    print(f\"duration  : {vlen}\")\n",
    "    print(f\"vid       : {vid}\")\n",
    "    print(f\"Q         : {query}\")\n",
    "    print(f\"prediction: {pred}\")\n",
    "    print(f\"gt.       : {gt}\")\n",
    "    cc.ipython_display(width=vw, maxduration=300)\n",
    "    cc.ipython_display(maxduration=300)\n",
    "\n",
    "\n",
    "    # draw query in text image\n",
    "    query = \"Q: \" + query\n",
    "    nlines = np.int64(np.ceil(len(query) / nw))\n",
    "    tline = []\n",
    "    for nl in range(nlines):\n",
    "        if nl == nlines-1:\n",
    "            cur_text = text_phantom(query[nl*nw:], vw)\n",
    "        else:\n",
    "            cur_text = text_phantom(query[nl*nw:nl*nw+nw], vw)\n",
    "        tline.append(cur_text)\n",
    "    q_text = np.concatenate(tline, axis=0)\n",
    "\n",
    "    # draw bar for GT and prediction\n",
    "    gt_idx = np.round(np.asarray(gt) / vlen * vw).astype(np.int64)\n",
    "    pred_idx = np.round(np.asarray(pred) / vlen * vw).astype(np.int64)\n",
    "    gt_mask, pred_mask = np.zeros((1,vw,3)), np.zeros((1,vw,3))\n",
    "    gt_mask[0, gt_idx[0]:gt_idx[1], 0] = 255 # Red color\n",
    "    pred_mask[0, pred_idx[0]:pred_idx[1], 2] = 255 # blue color\n",
    "    # expand masks for better visualization and concatenate them\n",
    "    bar = np.concatenate([expand_mask(gt_mask, margin=4), expand_mask(pred_mask)], axis=0)\n",
    "    \n",
    "    def add_query_and_bar(frame):\n",
    "        \"\"\" Add GT/prediction bar into frame\"\"\"\n",
    "        return np.concatenate([q_text, frame, bar], axis=0)\n",
    "\n",
    "    final_clip = cc.fl_image(add_query_and_bar)\n",
    "    \n",
    "    if visualize:\n",
    "        final_clip.ipython_display(maxduration=300)\n",
    "    else:\n",
    "        os.makedirs(f\"visualization/{dt}/{policy}\", exist_ok=True)\n",
    "        save_to = f\"visualization/{dt}/{policy}/{vid}.mp4\"\n",
    "        final_clip.write_videofile(save_to, fps=final_clip.fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_output(dt):\n",
    "    if dt == \"anet\":\n",
    "        from src.dataset import anet\n",
    "\n",
    "        config_path = \"pretraied_models/anet/config.yml\"\n",
    "        config = io_utils.load_yaml(config_path)[\"test_loader\"]\n",
    "        config[\"in_memory\"] = False\n",
    "        D = anet.ActivityNetCaptionsDataset(config)\n",
    "\n",
    "        pred_path = \"pretraied_models/anet/agvmr-activitynet.json\"\n",
    "        preds = io_utils.load_json(pred_path)\n",
    "        vid_dir = \"data/anet/raw_videos/validation/\"\n",
    "        \n",
    "    elif dt == \"charades\":\n",
    "        from src.dataset import charades\n",
    "\n",
    "        config_path = \"pretrained_models/charades/config.yml\"\n",
    "        config = io_utils.load_yaml(config_path)[\"test_loader\"]\n",
    "        config[\"in_memory\"] = False\n",
    "        D = charades.CharadesDataset(config)\n",
    "\n",
    "        pred_path = \"pretrained_models/charades/agvmr-charades.json\"\n",
    "        preds = io_utils.load_json(pred_path)\n",
    "        vid_dir = \"data/charades/raw_videos/\"\n",
    "    \n",
    "    return D, preds, vid_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load yaml file from pretrained_models/charades_LGI/config.yml\n",
      "Load json file from E:/experiment/TKDE/lgi/LGI4temporalgrounding-master/data/charades/data/charades\\preprocess\\query_info\\test_info_F1_L10_I3D.json\n",
      "Load json file from E:/agvmr/charades/AGVMR/epoch-01.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vids</th>\n",
       "      <th>qids</th>\n",
       "      <th>query</th>\n",
       "      <th>gts</th>\n",
       "      <th>predictions</th>\n",
       "      <th>durations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3MSZA</td>\n",
       "      <td>0</td>\n",
       "      <td>person turn a light on</td>\n",
       "      <td>[24.3, 30.4]</td>\n",
       "      <td>[[22.181608657836914, 30.689296789169312]]</td>\n",
       "      <td>30.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    vids qids                   query           gts  \\\n",
       "0  3MSZA    0  person turn a light on  [24.3, 30.4]   \n",
       "\n",
       "                                  predictions  durations  \n",
       "0  [[22.181608657836914, 30.689296789169312]]      30.96  "
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dt = \"charades\" # among anet|charades\n",
    "D, preds, vid_dir = load_output(dt)\n",
    "# print(preds['durations'])\n",
    "# print(preds['qids'])\n",
    "# print(preds['vids'])\n",
    "# print(preds['gts'])\n",
    "# print(preds['predictions'])\n",
    "\n",
    "query_tot = []\n",
    "for i in preds['qids']:\n",
    "    # print(i)\n",
    "    query = \" \".join(D.anns[i][\"tokens\"])\n",
    "    query_tot.append(query)\n",
    "\n",
    "data = {\n",
    "    'vids': preds['vids'],\n",
    "    'qids': preds['qids'],\n",
    "    'query': query_tot,\n",
    "    'gts': preds['gts'],\n",
    "    'predictions': preds['predictions'],\n",
    "    'durations': preds['durations']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "str = 'person turn a light on'\n",
    "result = df[df['query'] == str]\n",
    "result\n",
    "# result['vids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_result_video1(preds, D, dt, vid_dir, result, visualize=True):\n",
    "    # sampling index and fetching relevant information\n",
    "    #policy = \"success\" # among [\"random\" | \"success\" | \"failure\"]\n",
    "    # idx = sampling_idx(preds, policy)\n",
    "\n",
    "    \n",
    "    vlen = result['durations']\n",
    "    qid = result['qids']\n",
    "    pred = result['predictions']\n",
    "    gt = result['gts']\n",
    "    vid = result['vids']\n",
    "    query = \" \".join(D.anns[qid][\"tokens\"])\n",
    "    assert vid == D.anns[qid][\"video_id\"], \"{} != {}\".format(vid, D.anns[qid][\"video_id\"])\n",
    "    assert vlen == D.anns[qid][\"duration\"], \"{} != {}\".format(vlen, D.anns[qid][\"duration\"])\n",
    "\n",
    "    # concatenate two videos where one for GT (red) and another for prediction (blue)\n",
    "    vw, mg, nw = 480, 20, 50 # video_width, margin, number of words at each line\n",
    "    if dt == \"anet\":\n",
    "        vname = vid[2:] + \".mp4\"\n",
    "    elif dt == \"charades\":\n",
    "        vname = vid + \".mp4\"\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "    vid_path = vid_dir + vname\n",
    "    print(f\"video path: {vid_path}\")\n",
    "    vid_GT = concatenate_videoclips([\n",
    "        VideoFileClip(vid_path,audio=False).subclip(0, gt[0]).margin(mg),\n",
    "        VideoFileClip(vid_path,audio=False).subclip(gt[0], min(gt[1],vlen)).margin(mg, color=(255,0,0)), # red\n",
    "        VideoFileClip(vid_path,audio=False).subclip(min(gt[1],vlen), vlen).margin(mg),\n",
    "        ])\n",
    "    vid_pred = concatenate_videoclips([\n",
    "        VideoFileClip(vid_path,audio=False).subclip(0, pred[0]).margin(mg),\n",
    "        VideoFileClip(vid_path,audio=False).subclip(pred[0], min(pred[1],vlen)).margin(mg, color=(0,0,255)), # blue\n",
    "        VideoFileClip(vid_path,audio=False).subclip(min(pred[1],vlen), vlen).margin(mg),\n",
    "        ])\n",
    "    cc = clips_array([[vid_GT, vid_pred]]).resize(width=vw)\n",
    "    if FAST:\n",
    "        if dt == \"charades\":\n",
    "            factor = np.round(vlen / 20)\n",
    "        else:\n",
    "            factor = np.round(vlen / 30)\n",
    "        print(f\"speedup factor: {factor}\")\n",
    "        cc = cc.speedx(factor=factor)\n",
    "    print(f\"duration  : {vlen}\")\n",
    "    print(f\"vid       : {vid}\")\n",
    "    print(f\"Q         : {query}\")\n",
    "    print(f\"prediction: {pred}\")\n",
    "    print(f\"gt.       : {gt}\")\n",
    "    cc.ipython_display(width=vw, maxduration=300)\n",
    "    cc.ipython_display(maxduration=300)\n",
    "\n",
    "    # draw query in text image\n",
    "    query = \"Q: \" + query\n",
    "    nlines = np.int64(np.ceil(len(query) / nw))\n",
    "    tline = []\n",
    "    for nl in range(nlines):\n",
    "        if nl == nlines-1:\n",
    "            cur_text = text_phantom(query[nl*nw:], vw)\n",
    "        else:\n",
    "            cur_text = text_phantom(query[nl*nw:nl*nw+nw], vw)\n",
    "        tline.append(cur_text)\n",
    "    q_text = np.concatenate(tline, axis=0)\n",
    "\n",
    "    # draw bar for GT and prediction\n",
    "    gt_idx = np.round(np.asarray(gt) / vlen * vw).astype(np.int64)\n",
    "    pred_idx = np.round(np.asarray(pred) / vlen * vw).astype(np.int64)\n",
    "    gt_mask, pred_mask = np.zeros((1,vw,3)), np.zeros((1,vw,3))\n",
    "    gt_mask[0, gt_idx[0]:gt_idx[1], 0] = 255 # Red color\n",
    "    pred_mask[0, pred_idx[0]:pred_idx[1], 2] = 255 # blue color\n",
    "    # expand masks for better visualization and concatenate them\n",
    "    bar = np.concatenate([expand_mask(gt_mask, margin=4), expand_mask(pred_mask)], axis=0)\n",
    "    \n",
    "    def add_query_and_bar(frame):\n",
    "        \"\"\" Add GT/prediction bar into frame\"\"\"\n",
    "        return np.concatenate([q_text, frame, bar], axis=0)\n",
    "\n",
    "\n",
    "    final_clip = cc.fl_image(add_query_and_bar)\n",
    "    \n",
    "    if visualize:\n",
    "        final_clip.ipython_display(maxduration=300)\n",
    "    else:\n",
    "        os.makedirs(f\"visualization/{dt}\", exist_ok=True)\n",
    "        save_to = f\"visualization/{dt}/{vid}.mp4\"\n",
    "        final_clip.write_videofile(save_to, fps=final_clip.fps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create result videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    make_result_video(preds, D, dt, vid_dir, \"success\", visualize=True)\n",
    "    # except:\n",
    "    #     print(\"error occured :(\")\n",
    "    #     continue\n",
    "\n",
    "\n",
    "# for i in range(1):\n",
    "#     try:\n",
    "#         make_result_video(preds, D, dt, vid_dir, \"failure\", visualize=False)\n",
    "#     except:\n",
    "#         print(\"error occured :(\")\n",
    "#         continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7866\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def greet(name):\n",
    "    return \"Hello, \" + name + \"!\" \n",
    "\n",
    "\n",
    "def video_identity(query):\n",
    "    path = '__temp__.mp4'\n",
    "    return path\n",
    "\n",
    "\n",
    "demo = gr.Interface(video_identity, \n",
    "                    gr.Video(), \n",
    "                    \"playable_video\", \n",
    "                    )\n",
    "\n",
    "\t\n",
    "demo.launch(share=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
